<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Singular value problems · KrylovKit.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>KrylovKit.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../intro/">Introduction</a></li><li><a class="toctext" href="../linear/">Linear problems</a></li><li><a class="toctext" href="../eig/">Eigenvalue problems</a></li><li class="current"><a class="toctext" href>Singular value problems</a><ul class="internal"></ul></li><li><a class="toctext" href="../matfun/">Functions of matrices and linear maps</a></li><li><a class="toctext" href="../algorithms/">Available algorithms</a></li><li><a class="toctext" href="../implementation/">Details of the implementation</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Manual</li><li><a href>Singular value problems</a></li></ul><a class="edit-page" href="https://github.com/Jutho/KrylovKit.jl/blob/master/docs/src/man/svd.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Singular value problems</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Singular-value-problems-1" href="#Singular-value-problems-1">Singular value problems</a></h1><p>Computing a few singular values and corresponding left and right singular vectors is done using the function <code>svdsolve</code>:</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="KrylovKit.svdsolve" href="#KrylovKit.svdsolve"><code>KrylovKit.svdsolve</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">svdsolve(A::AbstractMatrix, [howmany = 1, which = :LR, T = eltype(A)]; kwargs...)
svdsolve(f, m::Int, [howmany = 1, which = :LR, T = Float64]; kwargs...)
svdsolve(f, x₀, [howmany = 1, which = :LM]; kwargs...)
svdsolve(f, x₀, howmany, which, algorithm)</code></pre><p>Compute <code>howmany</code> singular values from the linear map encoded in the matrix <code>A</code> or by the function <code>f</code>. Return singular values, left and right singular vectors and a <code>ConvergenceInfo</code> structure.</p><p><strong>Arguments:</strong></p><p>The linear map can be an <code>AbstractMatrix</code> (dense or sparse) or a general function or callable object. Since both the action of the linear map and its adjoint are required in order to compute singular values, <code>f</code> can either be a tuple of two callable objects (each accepting a single argument), representing the linear map and its adjoint respectively, or, <code>f</code> can be a single callable object that accepts two input arguments, where the second argument is a flag that indicates whether the adjoint or the normal action of the linear map needs to be computed. The latter form still combines well with the <code>do</code> block syntax of Julia, as in</p><pre><code class="language-julia">vals, lvecs, rvecs, info = svdsolve(x₀, y₀, howmany, which; kwargs...) do (x, flag)
    if flag
        # y = compute action of adjoint map on x
    else
        # y = compute action of linear map on x
    end
    return y
end</code></pre><p>For a general linear map encoded using either the tuple or the two-argument form, the best approach is to provide a start vector <code>x₀</code> (in the codomain, i.e. column space, of the linear map). Alternatively, one can specify the number <code>m</code> of rows of the linear map, in which case <code>x₀ = rand(T, m)</code> is used, where the default value of <code>T</code> is <code>Float64</code>, unless specified differently. If an <code>AbstractMatrix</code> is used, a starting vector <code>x₀</code> does not need to be provided; it is chosen as <code>rand(T, size(A,1))</code>.</p><p>The next arguments are optional, but should typically be specified. <code>howmany</code> specifies how many singular values and vectors should be computed; <code>which</code> specifies which singular values should be targetted. Valid specifications of <code>which</code> are</p><ul><li><code>LR</code>: largest singular values</li><li><code>SR</code>: smallest singular values</li></ul><p>However, the largest singular values tend to converge more rapidly.</p><p><strong>Return values:</strong></p><p>The return value is always of the form <code>vals, lvecs, rvecs, info = svdsolve(...)</code> with</p><ul><li><code>vals</code>: a <code>Vector{&lt;:Real}</code> containing the singular values, of length at least <code>howmany</code>,   but could be longer if more singular values were converged at the same cost.</li><li><code>lvecs</code>: a <code>Vector</code> of corresponding left singular vectors, of the same length as   <code>vals</code>.</li><li><code>rvecs</code>: a <code>Vector</code> of corresponding right singular vectors, of the same length as   <code>vals</code>. Note that singular vectors are not returned as a matrix, as the linear map   could act on any custom Julia type with vector like behavior, i.e. the elements of the   lists <code>lvecs</code>(<code>rvecs</code>) are objects that are typically similar to the starting guess <code>y₀</code>   (<code>x₀</code>), up to a possibly different <code>eltype</code>. When the linear map is a simple   <code>AbstractMatrix</code>, <code>lvecs</code> and <code>rvecs</code> will be <code>Vector{Vector{&lt;:Number}}</code>.</li><li><code>info</code>: an object of type [<code>ConvergenceInfo</code>], which has the following fields<ul><li><code>info.converged::Int</code>: indicates how many singular values and vectors were actually   converged to the specified tolerance <code>tol</code> (see below under keyword arguments)</li><li><code>info.residual::Vector</code>: a list of the same length as <code>vals</code> containing the   residuals   <code>info.residual[i] = A * rvecs[i] - vals[i] * lvecs[i]</code>.</li><li><code>info.normres::Vector{&lt;:Real}</code>: list of the same length as <code>vals</code> containing the   norm of the residual <code>info.normres[i] = norm(info.residual[i])</code></li><li><code>info.numops::Int</code>: number of times the linear map was applied, i.e. number of times   <code>f</code> was called, or a vector was multiplied with <code>A</code> or <code>A&#39;</code>.</li><li><code>info.numiter::Int</code>: number of times the Krylov subspace was restarted (see below)</li></ul></li></ul><div class="admonition warning"><div class="admonition-title">Check for convergence</div><div class="admonition-text"><p>No warning is printed if not all requested eigenvalues were converged, so always check if <code>info.converged &gt;= howmany</code>.</p></div></div><p><strong>Keyword arguments:</strong></p><p>Keyword arguments and their default values are given by:</p><ul><li><code>verbosity::Int = 0</code>: verbosity level, i.e. 0 (no messages), 1 (single message   at the end), 2 (information after every iteration), 3 (information per Krylov step)</li><li><code>krylovdim</code>: the maximum dimension of the Krylov subspace that will be constructed.   Note that the dimension of the vector space is not known or checked, e.g. <code>x₀</code> should   not necessarily support the <code>Base.length</code> function. If you know the actual problem   dimension is smaller than the default value, it is useful to reduce the value of   <code>krylovdim</code>, though in principle this should be detected.</li><li><code>tol</code>: the requested accuracy according to <code>normres</code> as defined above. If you work in   e.g. single precision (<code>Float32</code>), you should definitely change the default value.</li><li><code>maxiter</code>: the number of times the Krylov subspace can be rebuilt; see below for further   details on the algorithms.</li><li><code>orth</code>: the orthogonalization method to be used, see <a href="man/@ref"><code>Orthogonalizer</code></a></li></ul><p><strong>Algorithm</strong></p><p>The last method, without default values and keyword arguments, is the one that is finally called, and can also be used directly. Here the algorithm is specified, though currently only <a href="../algorithms/#KrylovKit.GKL"><code>GKL</code></a> is available. <code>GKL</code> refers to the the partial Golub-Kahan-Lanczos bidiagonalization which forms the basis for computing the approximation to the singular values. This factorization is dynamically shrunk and expanded (i.e. thick restart) similar to the Krylov-Schur factorization for eigenvalues.</p></div></div><a class="source-link" target="_blank" href="https://github.com/Jutho/KrylovKit.jl/blob/47b8ef34e3ebe394f59fce51c44a849826f51065/src/eigsolve/svdsolve.jl#L1-L94">source</a></section><footer><hr/><a class="previous" href="../eig/"><span class="direction">Previous</span><span class="title">Eigenvalue problems</span></a><a class="next" href="../matfun/"><span class="direction">Next</span><span class="title">Functions of matrices and linear maps</span></a></footer></article></body></html>
