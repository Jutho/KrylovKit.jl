<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · KrylovKit.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>KrylovKit.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Overview-1">Overview</a></li><li><a class="toctext" href="#Package-features-and-alternatives-1">Package features and alternatives</a></li><li><a class="toctext" href="#Current-functionality-1">Current functionality</a></li><li><a class="toctext" href="#Future-functionality?-1">Future functionality?</a></li></ul></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="man/intro/">Introduction</a></li><li><a class="toctext" href="man/linear/">Linear problems</a></li><li><a class="toctext" href="man/eig/">Eigenvalue problems</a></li><li><a class="toctext" href="man/svd/">Singular value problems</a></li><li><a class="toctext" href="man/matfun/">Functions of matrices and linear maps</a></li><li><a class="toctext" href="man/algorithms/">Available algorithms</a></li><li><a class="toctext" href="man/implementation/">Details of the implementation</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul><a class="edit-page" href="https://github.com/Jutho/KrylovKit.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="KrylovKit.jl-1" href="#KrylovKit.jl-1">KrylovKit.jl</a></h1><p>A Julia package collecting a number of Krylov-based algorithms for linear problems, singular value and eigenvalue problems and the application of functions of linear maps or operators to vectors.</p><h2><a class="nav-anchor" id="Overview-1" href="#Overview-1">Overview</a></h2><p>KrylovKit.jl accepts general functions or callable objects as linear maps, and general Julia objects with vector like behavior (see below) as vectors.</p><p>The high level interface of KrylovKit is provided by the following functions:</p><ul><li><a href="man/linear/#KrylovKit.linsolve"><code>linsolve</code></a>: solve linear systems <code>A*x = b</code></li><li><a href="man/eig/#KrylovKit.eigsolve"><code>eigsolve</code></a>: find a few eigenvalues and corresponding eigenvectors of an   eigenvalue problem <code>A*x = λ x</code></li><li><a href="man/eig/#KrylovKit.geneigsolve"><code>geneigsolve</code></a>: find a few eigenvalues and corresponding vectors of a   generalized eigenvalue problem <code>A*x = λ*B*x</code></li><li><a href="man/svd/#KrylovKit.svdsolve"><code>svdsolve</code></a>: find a few singular values and corresponding left and right   singular vectors <code>A*x = σ * y</code> and <code>A&#39;*y = σ*x</code>.</li><li><a href="man/matfun/#KrylovKit.exponentiate"><code>exponentiate</code></a>: apply the exponential of a linear map to a vector</li><li><a href="man/matfun/#KrylovKit.expintegrator"><code>expintegrator</code></a>: exponential integrator for a linear non-homogeneous ODE,   generalization of <code>exponentiate</code></li></ul><h2><a class="nav-anchor" id="Package-features-and-alternatives-1" href="#Package-features-and-alternatives-1">Package features and alternatives</a></h2><p>This section could also be titled &quot;Why did I create KrylovKit.jl&quot;?</p><p>There are already a fair number of packages with Krylov-based or other iterative methods, such as</p><ul><li><a href="https://github.com/JuliaMath/IterativeSolvers.jl">IterativeSolvers.jl</a>: part of the   <a href="https://github.com/JuliaMath">JuliaMath</a> organisation, solves linear systems and least   square problems, eigenvalue and singular value problems</li><li><a href="https://github.com/JuliaSmoothOptimizers/Krylov.jl">Krylov.jl</a>: part of the   <a href="https://github.com/JuliaSmoothOptimizers">JuliaSmoothOptimizers</a> organisation, solves   linear systems and least square problems, specific for linear operators from   <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</a>.</li><li><a href="https://github.com/lruthotto/KrylovMethods.jl">KrylovMethods.jl</a>: specific for sparse   matrices</li><li><a href="https://github.com/acroy/Expokit.jl">Expokit.jl</a>: application of the matrix   exponential to a vector</li><li><a href="https://github.com/haampie/ArnoldiMethod.jl">ArnoldiMethod.jl</a>: Implicitly restarted   Arnoldi method for eigenvalues of a general matrix</li><li><a href="https://github.com/haampie/JacobiDavidson.jl">JacobiDavidson.jl</a>: Jacobi-Davidson   method for eigenvalues of a general matrix</li></ul><p>These packages have certainly inspired and influenced the development of KrylovKit.jl. However, KrylovKit.jl distinguishes itself from the previous packages in the following ways:</p><ol><li><p>KrylovKit accepts general functions to represent the linear map or operator that defines  the problem, without having to wrap them in a  <a href="https://github.com/Jutho/LinearMaps.jl"><code>LinearMap</code></a> or  <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl"><code>LinearOperator</code></a> type.  Of course, subtypes of <code>AbstractMatrix</code> are also supported. If the linear map (always  the first argument) is a subtype of <code>AbstractMatrix</code>, matrix vector multiplication is  used, otherwise it is applied as a function call.</p></li><li><p>KrylovKit does not assume that the vectors involved in the problem are actual subtypes  of <code>AbstractVector</code>. Any Julia object that behaves as a vector is supported, so in  particular higher-dimensional arrays or any custom user type that supports the  following functions (with <code>v</code> and <code>w</code> two instances of this type and <code>α, β</code> scalars  (i.e. <code>Number</code>)):</p><ul><li><code>Base.eltype(v)</code>: the scalar type (i.e. <code>&lt;:Number</code>) of the data in <code>v</code></li><li><code>Base.similar(v, [T::Type&lt;:Number])</code>: a way to construct additional similar vectors,   possibly with a different scalar type <code>T</code>.</li><li><code>Base.copyto!(w, v)</code>: copy the contents of <code>v</code> to a preallocated vector <code>w</code></li><li><code>LinearAlgebra.mul!(w, v, α)</code>: out of place scalar multiplication; multiply   vector <code>v</code> with scalar <code>α</code> and store the result in <code>w</code></li><li><code>LinearAlgebra.rmul!(v, α)</code>: in-place scalar multiplication of <code>v</code> with <code>α</code>; in   particular with <code>α = false</code>, <code>v</code> is initialized with all zeros</li><li><code>LinearAlgebra.axpy!(α, v, w)</code>: store in <code>w</code> the result of <code>α*v + w</code></li><li><code>LinearAlgebra.axpby!(α, v, β, w)</code>: store in <code>w</code> the result of <code>α*v + β*w</code></li><li><code>LinearAlgebra.dot(v,w)</code>: compute the inner product of two vectors</li><li><code>LinearAlgebra.norm(v)</code>: compute the 2-norm of a vector</li></ul><p>Furthermore, KrylovKit provides two types satisfying the above requirements that might  facilitate certain applications:</p><ul><li><a href="@ref"><code>RecursiveVec</code></a> can be used for grouping a set of vectors into a single   vector like structure (can be used recursively). The reason that e.g.   <code>Vector{&lt;:Vector}</code> cannot be used for this is that it returns the wrong <code>eltype</code>   and methods like <code>similar(v, T)</code> and <code>fill!(v, α)</code>   don&#39;t work correctly.</li><li><a href="@ref"><code>InnerProductVec</code></a> can be used to redefine the inner product (i.e. <code>dot</code>)   and corresponding norm (<code>norm</code>) of an already existing vector like object. The   latter should help with implementing certain type of preconditioners</li></ul></li></ol><h2><a class="nav-anchor" id="Current-functionality-1" href="#Current-functionality-1">Current functionality</a></h2><p>The following algorithms are currently implemented</p><ul><li><code>linsolve</code>: <a href="man/algorithms/#KrylovKit.CG"><code>CG</code></a>, <a href="man/algorithms/#KrylovKit.GMRES"><code>GMRES</code></a></li><li><code>eigsolve</code>: a Krylov-Schur algorithm (i.e. with tick restarts) for extremal eigenvalues   of normal (i.e. not generalized) eigenvalue problems, corresponding to   <a href="man/algorithms/#KrylovKit.Lanczos"><code>Lanczos</code></a> for real symmetric or complex hermitian linear maps, and to   <a href="man/algorithms/#KrylovKit.Arnoldi"><code>Arnoldi</code></a> for general linear maps.</li><li><code>geneigsolve</code>: an customized implementation of the inverse-free algorithm of Golub and   Ye for symmetric / hermitian generalized eigenvalue problems with positive definite   matrix <code>B</code> in the right hand side of the generalized eigenvalue problem <span>$A v = B v λ$</span>.   The Matlab implementation was described by Money and Ye and is known as <code>EIGIFP</code>; in   particular it extends the Krylov subspace with a vector corresponding to the step   between the current and previous estimate, analoguous to the locally optimal   preconditioned conjugate gradient method (LOPCG). In particular, with Krylov dimension   2, it becomes equivalent to the latter.</li><li><code>svdsolve</code>: finding largest singular values based on Golub-Kahan-Lanczos   bidiagonalization (see <a href="man/algorithms/#KrylovKit.GKL"><code>GKL</code></a>)</li><li><code>exponentiate</code>: a <a href="man/algorithms/#KrylovKit.Lanczos"><code>Lanczos</code></a> based algorithm for the action of the exponential of   a real symmetric or complex hermitian linear map.</li><li><code>expintegrator</code>: exponential integrator for a linear non-homogeneous ODE, computes a   linear combination of the so-called <code>ϕⱼ</code> functions which generalize <code>ϕ₀(z) = exp(z)</code>.</li></ul><h2><a class="nav-anchor" id="Future-functionality?-1" href="#Future-functionality?-1">Future functionality?</a></h2><p>Here follows a wish list / to-do list for the future. Any help is welcomed and appreciated.</p><ul><li>More algorithms, including biorthogonal methods:<ul><li>for <code>linsolve</code>: MINRES, BiCG, BiCGStab(l), IDR(s), ...</li><li>for <code>eigsolve</code>: BiLanczos, Jacobi-Davidson JDQR/JDQZ, subspace iteration (?), ...</li><li>for <code>geneigsolve</code>: trace minimization, block versions</li></ul></li><li>Support both in-place / mutating and out-of-place functions as linear maps</li><li>Least square problems</li><li>Nonlinear eigenvalue problems</li><li>Preconditioners</li><li>Refined Ritz vectors, Harmonic ritz values and vectors</li><li>Reuse memory for storing vectors when restarting algorithms</li><li>Block versions of the algorithms</li><li>More relevant matrix functions</li></ul><p>Partially done:</p><ul><li>Improved efficiency for the specific case where <code>x</code> is <code>Vector</code> (i.e. BLAS level 2   operations): any vector <code>v::AbstractArray</code> which has <code>IndexStyle(v) == IndexLinear()</code>   now benefits from a multithreaded (use <code>export JULIA_NUM_THREADS = x</code> with <code>x</code> the   number of threads you want to use) implementation that resembles BLAS level 2 style for   the vector operations, provided <code>ClassicalGramSchmidt()</code>, <code>ClassicalGramSchmidt2()</code> or   <code>ClassicalGramSchmidtIR()</code> is chosen as orthogonalization routine.</li></ul><footer><hr/><a class="next" href="man/intro/"><span class="direction">Next</span><span class="title">Introduction</span></a></footer></article></body></html>
